<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NotSoTechnical</title><link>https://hrmJ.github.io/blog/</link><description>Writing a phd with markdown in the humanities - and other notes from a wannabe developer</description><atom:link href="https://hrmJ.github.io/blog/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:juho.harme@gmail.com"&gt;Juho Härme&lt;/a&gt; </copyright><lastBuildDate>Thu, 13 Jun 2019 13:12:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Setting up a new bookdown project</title><link>https://hrmJ.github.io/blog/posts/setting-up-a-new-bookdown-project/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been excited about writing my research in
&lt;a href="https://rmarkdown.rstudio.com/"&gt;Rmarkdown&lt;/a&gt; for something like five years now,
and have written basically all my academic work with it. The biggest project
was my dissertation thesis, a monograph written entirely in Rmd.
When writing something that large, or, actually, anything you 
might want to split into different sections, you should definitely
check out a recent development in the Rmarkdown universe, namely, the &lt;a href="https://bookdown.org/yihui/bookdown/"&gt;Bookdown&lt;/a&gt;
package. In this post, I'll go through my basic setup 
of a new bookdown project.&lt;/p&gt;
&lt;h2&gt;1. Setting up the project folder&lt;/h2&gt;
&lt;p&gt;I start with a fresh new folder with the following structure:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;bookdown/
├── 01-intro.Rmd
├── aux
│   ├── preamble.tex
│   ├── refs.bib
│   └── utaltl.csl
├── _bookdown.yml
└── _output.yml
&lt;/pre&gt;


&lt;p&gt;Bookdown will try to get all the rmd files in the project folder
and turn them into a single document. To make sure you have the right 
order of files in the final output, it's safest to prefix the files
with numbers. &lt;/p&gt;
&lt;p&gt;The configuration of bookdown is done through the two &lt;a href="https://en.wikipedia.org/wiki/YAML"&gt;yaml&lt;/a&gt;
files, &lt;code&gt;_bookdown.yml&lt;/code&gt; and'&lt;code&gt;_output.yml&lt;/code&gt; AND with a yaml block
at the beginning of the first file of the project (in this case, &lt;code&gt;01-intro.Rmd&lt;/code&gt;).&lt;/p&gt;
&lt;h3&gt;Basic configuration&lt;/h3&gt;
&lt;p&gt;In a project I recently started, this is what the yaml block 
in &lt;code&gt;01-intro.Rmd&lt;/code&gt; looks like:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;latexBackend&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;linguex&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;exampleRefFormat&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'{}'&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;title&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'Last&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;year&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;but&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;not&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;yesterday?&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Explaining&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;differences&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;in&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;the&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;locations&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;of&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Finnish&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;and&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;Russian&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;time&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;adverbials&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;using&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;comparable&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;corpora'&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;author&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;Juho Härme&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;bibliography&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;aux/refs.bib&lt;/span&gt;
&lt;span class="l l-Scalar l-Scalar-Plain"&gt;link-citations&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l l-Scalar l-Scalar-Plain"&gt;true&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The options &lt;em&gt;latexBackend&lt;/em&gt; and &lt;em&gt;exampleRefFormat&lt;/em&gt; are specific 
to my projects: they have to do with using linguistic examples
in the text, which I do with my own fork of a &lt;a href="http://www.pandoc.org/filters.html"&gt;pandoc filter&lt;/a&gt;
called &lt;a href="https://github.com/hrmJ/pangloss_linguex"&gt;pangloss&lt;/a&gt;. These
lines should be left out if such a filter is not used.&lt;/p&gt;
&lt;p&gt;Bibliography management and different outputs, output modification using cls
or bib(la)tex and all those kinds of factors definitely deserve
a separate post. For simplicity's sake, here I only
use the default settings and simply define the location of the &lt;code&gt;.bib&lt;/code&gt;
file containing my references in the format of a bibtex database.&lt;/p&gt;
&lt;p&gt;The file &lt;code&gt;_bookdown.yaml&lt;/code&gt; is pretty simple, in this
project I only have one line:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;delete_merged_file&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
&lt;/pre&gt;


&lt;h3&gt;Output configuration&lt;/h3&gt;
&lt;p&gt;When writing Rmarkdown files, you can specify multiple output
formats in &lt;code&gt;_output.yml&lt;/code&gt; and if you compile your 
book with the &lt;a href="https://bookdown.org/yihui/bookdown/new-session.html"&gt;render_book function&lt;/a&gt;,
without additional arguments, all those output formats will be produced.&lt;/p&gt;
&lt;p&gt;Here, I have specified two output formats, &lt;em&gt;html&lt;/em&gt; and &lt;em&gt;pdf&lt;/em&gt; (produced with
latex). The html is something I use when sketching and building the article / book.
At that stage I usually have the pdf parts commented out. When the work is getting
closer to be finished, I tend to switch to the pdf output.&lt;/p&gt;
&lt;p&gt;Here's what my &lt;code&gt;_output.yml&lt;/code&gt; looks like&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;bookdown::gitbook:
bookdown::pdf_book:
  toc: true
  toc_depth: 6
  includes:
    in_header: aux/preamble.tex
  latex_engine: xelatex
  keep_tex: true
  pandoc_args:
    - --filter
    - pangloss
    - --filter
    - pandoc_avm
&lt;/pre&gt;


&lt;h3&gt;Auxiliary files&lt;/h3&gt;
&lt;p&gt;As can be seen in the folder structure above, I use a separate folder called &lt;em&gt;aux&lt;/em&gt; to store
my auxiliary files in. These include the bibliography database, possibly some additional pandoc
filters, cls files and the like. One especially important file is the &lt;code&gt;preamble.tex&lt;/code&gt;, which
loads all the needed latex packages and adjusts the final document's layout.&lt;/p&gt;
&lt;h2&gt;Compiling the book&lt;/h2&gt;
&lt;p&gt;I will probably write something about how to do this in Rstudio later on.
Here's how the compilation of the book happens in R terminal.&lt;/p&gt;
&lt;p&gt;First, make sure to (install and) load the bookdown library&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;bookdown&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Then, just run the &lt;code&gt;r render_book&lt;/code&gt; function by specifying at least one file to be included
in the book:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;render_book&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"01-intro.Rmd"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;I actually tend to have a separate &lt;code&gt;.Rprofile&lt;/code&gt; file
which includes all the libraries that need to be loaded
etc. Place the file in the project's directory and
you'll have you workspace set up the way you want it.&lt;/p&gt;
&lt;p&gt;After the compilation, you'll see that
the final output will end up in a folder called &lt;code&gt;_book&lt;/code&gt;
which also includes a whole bunch
of auxiliary files, especially for the gitbook type of html format.
Here's the structure of my bookdown folder
after the compilation process:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;bookdown/
├── 01-intro.Rmd
├── aux
│   ├── preamble.tex
│   ├── refs.bib
│   └── utaltl.csl
├── _book
│   ├── a-real-section.html
│   ├── introduction.html
│   ├── libs
│   │   ├── gitbook-2.6.7
│   │   │   ├── css
│   │   │   │   ├── fontawesome
│   │   │   │   │   └── fontawesome-webfont.ttf
│   │   │   │   ├── plugin-bookdown.css
│   │   │   │   ├── plugin-fontsettings.css
│   │   │   │   ├── plugin-highlight.css
│   │   │   │   ├── plugin-search.css
│   │   │   │   └── style.css
│   │   │   └── js
│   │   │       ├── app.min.js
│   │   │       ├── jquery.highlight.js
│   │   │       ├── lunr.js
│   │   │       ├── plugin-bookdown.js
│   │   │       ├── plugin-fontsettings.js
│   │   │       ├── plugin-search.js
│   │   │       └── plugin-sharing.js
│   │   └── jquery-2.2.3
│   │       └── jquery.min.js
│   ├── _main.pdf
│   ├── _main.tex
│   └── search_index.json
├── _bookdown.yml
└── _output.yml
&lt;/pre&gt;


&lt;p&gt;The actual pdf output is the file &lt;code&gt;_book/_main.pdf&lt;/code&gt;. For the html
output, just pick the  name of the first html file, in this case
&lt;code&gt;introduction.html&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>r rmarkdown bookdown</category><guid>https://hrmJ.github.io/blog/posts/setting-up-a-new-bookdown-project/</guid><pubDate>Tue, 06 Nov 2018 07:41:26 GMT</pubDate></item><item><title>Follow-up: more on xapers</title><link>https://hrmJ.github.io/blog/posts/follow-up-more-on-xapers/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;A follow-up on the previous post about gscholar and xapers.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Xapers is also quite useful in getting bibtex entries. If you know
the doi of a reference, a bibtex entry can be retrieved
by typing &lt;code&gt;xapers source2bib URL&lt;/code&gt;, 
e.g. &lt;code&gt;xapers source2bib doi:10.1214/009053604000001048&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or, why not, retrieve the paper to the local indexed database right away?
So, assuming we've found an article with a doi on the internet,
 we can run: &lt;code&gt;xapers add --source=doi:10.1214/009053604000001048&lt;/code&gt;
to add the paper to our index. If we also found a downloadable pdf,
we can specify it 
as well: &lt;code&gt;xapers add --source=doi:10.1214/009053604000001048 --file=/tmp/gelman2005.pdf&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To add a paper that was indexed this way to your local bibtex file, you can first use &lt;code&gt;xapers show&lt;/code&gt;
to view the entry in xapers and then hit &lt;code&gt;ALT-B&lt;/code&gt; on the entry. This copies the bibtex entry
of the paper to clipboard for you to paste it in your .bib file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;</description><category>references apps</category><guid>https://hrmJ.github.io/blog/posts/follow-up-more-on-xapers/</guid><pubDate>Wed, 08 Aug 2018 08:39:08 GMT</pubDate></item><item><title>App picks: gscholar, xapers</title><link>https://hrmJ.github.io/blog/posts/app-pick-gscholar/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;Just a quick shout-out to &lt;a href="https://github.com/venthur/gscholar"&gt;gscholar&lt;/a&gt;. 
Google scholar is, of course, a major part of my workflow in writing
articles. I especially often use it to quickly grab a bibtex entry for 
a reference I am using. Well, that process just got a nugde quicker, since
I found a command line app to search for the bibtex entries.&lt;/p&gt;
&lt;p&gt;It's a python app, so just &lt;code&gt;pip install gscholar&lt;/code&gt;. After that, run
a query, e.g.  &lt;code&gt;gscholar "gelman prior distributions for variance parameters"&lt;/code&gt;
and you'll immediately get a bibtex output, which you can for instance pipe
further to append to your &lt;code&gt;.bib&lt;/code&gt; file. Awesome!&lt;/p&gt;
&lt;p&gt;Here is the output of the example query above:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;@article{gelman2006prior,
  title={Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)},
  author={Gelman, Andrew and others},
  journal={Bayesian analysis},
  volume={1},
  number={3},
  pages={515--534},
  year={2006},
  publisher={International Society for Bayesian Analysis}
}
&lt;/pre&gt;


&lt;p&gt;Another related command line app worth mentioning is
&lt;a href="https://finestructure.net/xapers/"&gt;xapers&lt;/a&gt;. It's a tool for indexing all your
research-related pdfs into one big searchable databes of references. A full
&lt;code&gt;.bib&lt;/code&gt; file can be imported  (just add a &lt;code&gt;file={/pth/to/file.pdf}&lt;/code&gt; line to your
bibtex entries) by running &lt;code&gt;xapers import myrefs.bib&lt;/code&gt;. After the import, you
can search for any string that you remembered occured in some of the references
(but can't remember which one) by just &lt;code&gt;xapers search 'find this string'&lt;/code&gt;. If
the file was found, just hit enter to open it with your default pdf viewer
(&lt;a href="https://pwmt.org/projects/zathura/"&gt;zathura, right?&lt;/a&gt;) and repeat the search
there to get the page number.&lt;/p&gt;&lt;/div&gt;</description><category>apps</category><category>citations</category><category>command-line</category><guid>https://hrmJ.github.io/blog/posts/app-pick-gscholar/</guid><pubDate>Mon, 06 Aug 2018 09:22:09 GMT</pubDate></item><item><title>Annotating random samples part 2</title><link>https://hrmJ.github.io/blog/posts/annotating-random-samples-part-2/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;Just a quick follow-up on the previous post about manually annotating random
samples. Yesterday I was facing a situation where I had to go and find some
broader contexts for concordances fetched from a corpus of Finnish newspaper
texts. These corpora don't allow access for more than a sentence, maximum
a paragraph at a time, and I needed to look at whole texts. Luckily, I figured
out that the city library has access to the electronic archives of many of the
newspapers included in the corpus.&lt;/p&gt;
&lt;p&gt;So, I had a sample of 60 concordances I needed to get the full text for. The
access to the full texts was provided only through the computers physically
located in the library --  this meant that  I, sadly, didn't have the
possibility of working with just R all the time. The easiest solution I came up with 
was to quickly upload my data set to a Google sheet and then open that sheet 
in the browser of the PC at the library. Fortunately, there is the nice
&lt;a href="https://github.com/jennybc/googlesheets"&gt;googlesheets&lt;/a&gt; library that makes this easy.
All I had to do, was:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;devtools&lt;span class="o"&gt;::&lt;/span&gt;install_github&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"jennybc/googlesheets"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;googlesheets&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Then I converted an existing data frame (well, a tibble, actually), to a Google sheet by just:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;samp_gsheet &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gs_new&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"samp_press_fi"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;input&lt;span class="o"&gt;=&lt;/span&gt;samp_press_fi&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;...where &lt;code&gt;samp_press_fi&lt;/code&gt; was the name of my tibble including the samples
I wanted to get the contexts for. The command first takes you to Google
authorization page, after which you're good to go. The nice thing about 
googlesheets is, that after I got the contexts I needed, the data was automatically 
updated in R by just, for instance:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; samp_gsheet &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; gs_read
Accessing worksheet titled &lt;span class="s"&gt;'Sheet1'&lt;/span&gt;&lt;span class="m"&gt;.&lt;/span&gt;
Downloading&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="m"&gt;8.2&lt;/span&gt; kB     Parsed with column specification&lt;span class="o"&gt;:&lt;/span&gt;
cols&lt;span class="p"&gt;(&lt;/span&gt;
  sent &lt;span class="o"&gt;=&lt;/span&gt; col_character&lt;span class="p"&gt;(),&lt;/span&gt;
  sourcetext &lt;span class="o"&gt;=&lt;/span&gt; col_character&lt;span class="p"&gt;(),&lt;/span&gt;
  location3 &lt;span class="o"&gt;=&lt;/span&gt; col_character&lt;span class="p"&gt;(),&lt;/span&gt;
  group &lt;span class="o"&gt;=&lt;/span&gt; col_character&lt;span class="p"&gt;(),&lt;/span&gt;
  context &lt;span class="o"&gt;=&lt;/span&gt; col_character&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><category>googlesheets</category><category>r</category><category>sampling</category><guid>https://hrmJ.github.io/blog/posts/annotating-random-samples-part-2/</guid><pubDate>Wed, 30 May 2018 05:25:08 GMT</pubDate></item><item><title>Annotating random samples in R</title><link>https://hrmJ.github.io/blog/posts/annotating-random-samples-in-r/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;Years ago, when I was still working with my master's thesis, I used to do 
a lot of manual annotating of data in a spreadsheet software (libreoffice calc, mainly).
Now that R has firmly become my main tool for doing research, I've been thinking
about what's the best way to, for instance, manually annotate a small sample
of sentences from a data frame.&lt;/p&gt;
&lt;h3&gt;Random sampling with dplyr&lt;/h3&gt;
&lt;p&gt;First of all, I must say that during the last couple of months I've grown 
more and more accustomed to using &lt;a href="https://dplyr.tidyverse.org/"&gt;dplyr's&lt;/a&gt; piping and data
manipulation techniques. They have absolutely revolutionized the way I write
R code nowadays. Here's one typical use case for me that has to do with 
annotating samples.&lt;/p&gt;
&lt;p&gt;Consider &lt;a href="https://hrmJ.github.io/blog/posts/annotating-random-samples-in-r/" title="/data/headverbs.csv"&gt;this dataset&lt;/a&gt; consisting of Finnish and Russian verbs:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# A tibble: 543 x 2&lt;/span&gt;
&lt;span class="c1"&gt;# Groups:   lang [2]&lt;/span&gt;
   lang  headverb
   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt; fi    saada
 &lt;span class="m"&gt;2&lt;/span&gt; fi    tehdä
 &lt;span class="m"&gt;3&lt;/span&gt; ru    провести
 &lt;span class="m"&gt;4&lt;/span&gt; ru    принять
 &lt;span class="m"&gt;5&lt;/span&gt; ru    получить
 &lt;span class="m"&gt;6&lt;/span&gt; fi    voittaa
 &lt;span class="m"&gt;7&lt;/span&gt; ru    опубликовать
 &lt;span class="m"&gt;8&lt;/span&gt; fi    aloittaa
 &lt;span class="m"&gt;9&lt;/span&gt; fi    antaa
&lt;span class="m"&gt;10&lt;/span&gt; fi    ottaa
&lt;span class="c1"&gt;# ... with 533 more rows&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;If my goal were to take a random sample of these verbs, &lt;em&gt;dplyr&lt;/em&gt; offers the
convenient function &lt;code&gt;sample_n&lt;/code&gt;. So I can just do:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; headverbs &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; sample_n&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# A tibble: 10 x 2&lt;/span&gt;
   lang  headverb
   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt; ru    вынести
 &lt;span class="m"&gt;2&lt;/span&gt; ru    приговорить
 &lt;span class="m"&gt;3&lt;/span&gt; fi    ampua
 &lt;span class="m"&gt;4&lt;/span&gt; ru    пройти
 &lt;span class="m"&gt;5&lt;/span&gt; fi    nimittää
 &lt;span class="m"&gt;6&lt;/span&gt; ru    сдать
 &lt;span class="m"&gt;7&lt;/span&gt; ru    предложить
 &lt;span class="m"&gt;8&lt;/span&gt; ru    заказывать
 &lt;span class="m"&gt;9&lt;/span&gt; ru    запретить
&lt;span class="m"&gt;10&lt;/span&gt; fi    määrätä
&lt;/pre&gt;


&lt;p&gt;Even better, using the &lt;code&gt;group_by&lt;/code&gt; function, I can first group my data by language
and then get a sample having &lt;code&gt;n&lt;/code&gt; number of instances from both Finnish and Russian:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; headverbs &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class="p"&gt;(&lt;/span&gt;lang&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; sample_n&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# A tibble: 20 x 2&lt;/span&gt;
&lt;span class="c1"&gt;# Groups:   lang [2]&lt;/span&gt;
   lang  headverb
   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;chr&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt; fi    käydä
 &lt;span class="m"&gt;2&lt;/span&gt; fi    avata
 &lt;span class="m"&gt;3&lt;/span&gt; fi    korottaa
 &lt;span class="m"&gt;4&lt;/span&gt; fi    pistää
 &lt;span class="m"&gt;5&lt;/span&gt; fi    osoittaa
 &lt;span class="m"&gt;6&lt;/span&gt; fi    uudistaa
 &lt;span class="m"&gt;7&lt;/span&gt; fi    korjata
 &lt;span class="m"&gt;8&lt;/span&gt; fi    kilpailuttaa
 &lt;span class="m"&gt;9&lt;/span&gt; fi    todistaa
&lt;span class="m"&gt;10&lt;/span&gt; fi    pelata
&lt;span class="m"&gt;11&lt;/span&gt; ru    обыграть
&lt;span class="m"&gt;12&lt;/span&gt; ru    проиграть
&lt;span class="m"&gt;13&lt;/span&gt; ru    представлять
&lt;span class="m"&gt;14&lt;/span&gt; ru    опубликовать
&lt;span class="m"&gt;15&lt;/span&gt; ru    решить
&lt;span class="m"&gt;16&lt;/span&gt; ru    комментировать
&lt;span class="m"&gt;17&lt;/span&gt; ru    свести
&lt;span class="m"&gt;18&lt;/span&gt; ru    испечь
&lt;span class="m"&gt;19&lt;/span&gt; ru    перенести
&lt;span class="m"&gt;20&lt;/span&gt; ru    взорвать
&lt;/pre&gt;


&lt;h3&gt;Manual annotations&lt;/h3&gt;
&lt;p&gt;Now, in order to make manual annotations possible without leaving R I 
wrote the following little function:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;CheckSample_df &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;r&lt;span class="p"&gt;,&lt;/span&gt; cols_to_show&lt;span class="p"&gt;,&lt;/span&gt; backup_file&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/tmp/backup.txt"&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    content  &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;sapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;r&lt;span class="p"&gt;[&lt;/span&gt;cols_to_show&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;strwrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;79&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;collapse&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="kp"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\n\n"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cols_to_show&lt;span class="p"&gt;,&lt;/span&gt;content&lt;span class="p"&gt;,&lt;/span&gt;sep&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"\n=====\n"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;collapse&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"\n\n"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;"\n\n"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    def &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;readline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\nYour annotation:\n"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    write_lines&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;paste0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                       &lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;r&lt;span class="p"&gt;[&lt;/span&gt;cols_to_show&lt;span class="p"&gt;],&lt;/span&gt;collapse&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"|"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                       &lt;span class="s"&gt;"|"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;def&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="p"&gt;,&lt;/span&gt;backup_file&lt;span class="p"&gt;,&lt;/span&gt;append&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;def&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The function is designed to be called with &lt;code&gt;apply&lt;/code&gt; (for a tutorial cf. e.g
&lt;a href="https://www.datacamp.com/community/tutorials/r-tutorial-apply-family"&gt;here&lt;/a&gt;). 
For the verb dataset above, if
I wanted to define an additional column describing, e.g., my interpretation of
the semantic class of each verb, I could do the following:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;headverbs&lt;span class="o"&gt;$&lt;/span&gt;semantic_class &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;headverbs&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;CheckSample_df&lt;span class="p"&gt;,&lt;/span&gt; cols_to_show&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"lang"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"headverb"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The &lt;code&gt;cols_to_show&lt;/code&gt; parameter defines, which columns are shown for the user to
help with the annotation. The &lt;code&gt;backup_file&lt;/code&gt; specifies a file the function copies
the annotation results. This is a reasonable thing to do especially if you have a
lot to annotate -- in case of R crashing in the middle of the process, 
it's nice to have something to use as a basis for data recovery.&lt;/p&gt;
&lt;p&gt;If you're just interested in a simpler version that
you can use with &lt;code&gt;sapply&lt;/code&gt; , the function could be written this way:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;CheckSample_simple &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;show_this&lt;span class="p"&gt;,&lt;/span&gt; backup_file&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"/tmp/backup.txt"&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="kp"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\n\n"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;strwrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;show_this&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; collapse&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;"\n\n"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    def &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;readline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Your annotation:"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    write_lines&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;paste0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;show_this&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"|"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;def&lt;span class="p"&gt;),&lt;/span&gt;backup_file&lt;span class="p"&gt;,&lt;/span&gt;append&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;def&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;h4&gt;Fine-tuning with pbapply&lt;/h4&gt;
&lt;p&gt;One improvement to the aforementioned technique is to get some feedback on how
you are progressing with the annotation process. A great tool for 
this is the &lt;a href="https://github.com/psolymos/pbapply"&gt;pbapply&lt;/a&gt; package. We can
just turn the previous command into:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;headverbs&lt;span class="o"&gt;$&lt;/span&gt;semantic_class &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; pbapply&lt;span class="p"&gt;(&lt;/span&gt;headverbs&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;CheckSample_df&lt;span class="p"&gt;,&lt;/span&gt; cols_to_show&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"lang"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"headverb"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;And we get a nice progress bar indicating the work that has already been done
+ an estimate of the time remaining:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;   &lt;span class="o"&gt;|+++++&lt;/span&gt;                                             &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="m"&gt;9&lt;/span&gt; % &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="m"&gt;02&lt;/span&gt;m &lt;span class="m"&gt;22&lt;/span&gt;s
&lt;/pre&gt;&lt;/div&gt;</description><category>dplyr</category><category>r</category><category>sampling</category><guid>https://hrmJ.github.io/blog/posts/annotating-random-samples-in-r/</guid><pubDate>Mon, 07 May 2018 11:34:08 GMT</pubDate></item><item><title>Getting readable pdfs from scans</title><link>https://hrmJ.github.io/blog/posts/getting-readable-pdfs-from-scans/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;Buying the Onyx boox N96ml reader (with 9 inch display and android os)
last spring quite literally revolutionized my reading of
ebooks. It's not so often nowadays that I face  a situation
where I actually need to &lt;em&gt;scan&lt;/em&gt; a book in order to have it
as a digital version. Sometimes this still happens,
however -- especially with certain not--so--recent dissertations that are not available
in our university library. This was the case with 
Knud Lambrecht's seminal &lt;em&gt;Information structure and sentence form: Topic, focus, and the mental representations of discourse referents&lt;/em&gt;
(from 1996), which I acquired through an interlibrary loan and 
only had a limited time to read. I had actually 
scanned the book long ago, but ended up with just a raw 
unedited pdf with two pages per sheet -- certainly
not ideal for e-ink displays.&lt;/p&gt;
&lt;p&gt;So I finally got tired of reading the book on 
a desktop computer and decided I could try
to improve the file a bit. In the past I 
had been working a lot with a utility called &lt;a href="http://scantailor.org/"&gt;ScanTailor&lt;/a&gt;.
This is a tool that takes multi-color tif files as input and 
outputs (in the ideal case) nice and clear black--and--white
tifs with nothing but the actual text left. ScanTailor tries to strip
away all noise such as illuminations and shadows. It automatically splits
pages, adjusts their orientation and, finally, tries to 
 "dewarp" and "despeckle" the
pages. &lt;/p&gt;
&lt;p&gt;Here's my work flow with ScanTailor, if I'm starting with a multi-page pdf.&lt;/p&gt;
&lt;h3&gt;1. Convert the pdf to a single multi-page tif&lt;/h3&gt;
&lt;p&gt;As I noted above, ScanTailor doesn't accept pdfs as input, so I had to convert
my pdf to tif. Here's a trick I've learned with ghostscript:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;gs -sDEVICE&lt;span class="o"&gt;=&lt;/span&gt;tiff24nc -r300x300 -sOutputFile&lt;span class="o"&gt;=&lt;/span&gt;my_new_tif.tif -- my_original_pdf.pdf&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;/pre&gt;


&lt;h3&gt;2. Split the multi-page tif to individual files&lt;/h3&gt;
&lt;p&gt;I used to use ScanTailor's GUI version, which let's you tweak with individual pages
and see the results immediately. This was rather laborious, and you actually had to
go through every single page (in my current case it would have meant 396 pages).
It wasn't until recently that I actually discovered that ScanTailor
also has a command line version called scantailor-cli. The command-line version
cannot handle multi-page input, so I had to add an extra step to my work flow,
namely, converting the multi-page tif I just got from ghostscript to 
multiple single-page tifs. This turned out to be harder than I first thought,
mainly because the tif was so large. I finally found this solution from StackOverflow
and modified it a bit.
It requires you to specify the number of pages in the tif.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;mkdir split
&lt;span class="nv"&gt;END&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;NUMBER_OF_PAGES&amp;gt;&lt;span class="p"&gt;;&lt;/span&gt; 
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;i&amp;lt;&lt;span class="o"&gt;=&lt;/span&gt;END&lt;span class="p"&gt;;&lt;/span&gt;i++&lt;span class="o"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt; 
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$i&lt;/span&gt; 
    convert my_new_tif.tif&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$i&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; -scene &lt;span class="m"&gt;1&lt;/span&gt; split/my_new_tif_&lt;span class="nv"&gt;$i&lt;/span&gt;.tif
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;


&lt;h3&gt;3. Running scantailor&lt;/h3&gt;
&lt;p&gt;So I ended up having a folder named &lt;code&gt;split&lt;/code&gt; full of individual tifs, which
is exactly what scantailor-cli needed. The command line version has a lot of 
options you can tweak, but for me the default settings worked like a charm.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;mkdir output
scantailor-cli split output
&lt;/pre&gt;


&lt;h3&gt;4. Modifying the file names&lt;/h3&gt;
&lt;p&gt;As a result of the previous command, I got a bunch of nicely formatted black
and white tif files in a folder called &lt;code&gt;output&lt;/code&gt;. Before I could try to merge
these into a single file again, I had to do some renaming. Oh, by the way,
forgot to mention: all this is done on a linux machine (ubuntu 17.10).
I had to install the packages &lt;code&gt;libtiff-tools&lt;/code&gt;, &lt;code&gt;pdftk&lt;/code&gt; and &lt;code&gt;rename&lt;/code&gt; for the next two
steps to work.&lt;/p&gt;
&lt;p&gt;This is what I did to rename my tifs so that they could be merged in exactly
the right order (found the solution &lt;a href="https://askubuntu.com/questions/473236/renaming-hundreds-of-files-at-once-for-proper-sorting"&gt;from askubuntu&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;rename &lt;span class="s1"&gt;'s/\d+/sprintf("%05d", $&amp;amp;)/e'&lt;/span&gt; *.tif
&lt;/pre&gt;


&lt;h3&gt;5. Combining  and converting&lt;/h3&gt;
&lt;p&gt;After the renaming, I just combined the tifs with &lt;code&gt;tiffcp&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;tiffcp *tif output.tif
&lt;/pre&gt;


&lt;p&gt;The last step was to convert the tiff back to pdf:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;tiff2pdf output.tif -o output.pdf
&lt;/pre&gt;


&lt;p&gt;All this resulted in a nice 16MB (396 pages) pdf file that
was perfectly fine for reading with an e-ink device.&lt;/p&gt;&lt;/div&gt;</description><category>ebooks</category><category>onyx boox</category><category>pdf</category><category>scanning</category><category>scantailor</category><category>tif</category><guid>https://hrmJ.github.io/blog/posts/getting-readable-pdfs-from-scans/</guid><pubDate>Fri, 02 Feb 2018 14:33:25 GMT</pubDate></item><item><title>The setNames + (l)apply pattern</title><link>https://hrmJ.github.io/blog/posts/the-setnames-%2B-lapply-pattern/</link><dc:creator>Juho Härme</dc:creator><description>&lt;div&gt;&lt;p&gt;My research is, most of the time, about the differences and similarities
between two languages, Finnish and Russian. Most of the stuff I deal with
is quantitative by methodology and I tend to have large datasets in 
the following format:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;lang  &lt;/th&gt;
&lt;th&gt;variable_A  &lt;/th&gt;
&lt;th&gt;variable_B  &lt;/th&gt;
&lt;th&gt;variable_C&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;category b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;z&lt;/td&gt;
&lt;td&gt;51&lt;/td&gt;
&lt;td&gt;category b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ru&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;category b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ru&lt;/td&gt;
&lt;td&gt;z&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ru&lt;/td&gt;
&lt;td&gt;z&lt;/td&gt;
&lt;td&gt;88&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ru&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;category b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;fi&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;32&lt;/td&gt;
&lt;td&gt;category b&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ru&lt;/td&gt;
&lt;td&gt;x&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;category a&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;My usual way of getting some quick numbers out of the data for both of the
languages is to use lists rather than single variables. E.g.
instead of  having:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    number_of_xyz_FI &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'fi'&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    number_of_xyz_RU &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'ru'&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;I prefer:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    number_of_xyz &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s"&gt;"fi"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'fi'&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="s"&gt;"ru"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'ru'&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Now I can reference the data in my inline text with &lt;code&gt;number_of_xyz$fi&lt;/code&gt; and &lt;code&gt;number_of_xyz$ru&lt;/code&gt;.
This makes the global namespace less messy and looks more logical, in my opinion, at least.
There is still one downside to all of this: from the perspective of reproducibility 
of the code and in order not to break the &lt;a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"&gt;DRY&lt;/a&gt;
principle, it would be good to have the members of the list set up inside a loop.
So I usually end up using  &lt;code&gt;lapply&lt;/code&gt;, acting on a vector of language codes:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    number_of_xyz &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"fi"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"ru"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;thislang&lt;span class="p"&gt;){&lt;/span&gt;
        &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;==&lt;/span&gt; thislang &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;This still has the downside, that I have to manually set the names of the produced list, i.e.&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;number_of_xyz&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"fi"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"ru"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;which is somewhat annoying. Of course -- in the spirit of DRY, once again -- it's better to have
the language codes set up as a separate variable beforehand, so that the whole thing becomes&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;langs &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"fi"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"ru"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

number_of_xyz &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;langs&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;thislang&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;==&lt;/span&gt; thislang &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;number_of_xyz&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; langs
&lt;/pre&gt;


&lt;p&gt;Luckily, some time ago I found at StackOverflow a neater way to do this. The trick is 
to use the &lt;code&gt;setNames&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;langs &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"fi"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;"ru"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

number_of_xyz &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; setNames&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;langs&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;thislang&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="kp"&gt;nrow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;mydata&lt;span class="p"&gt;,&lt;/span&gt;lang &lt;span class="o"&gt;==&lt;/span&gt; thislang &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_A &lt;span class="o"&gt;==&lt;/span&gt; x &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; variable_B &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;},&lt;/span&gt;langs&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;...and this whole pattern has become a real habit for me, so that every time I do a comparison,
I almost immediately write &lt;code&gt;setNames(lang,function(thislang),langs)&lt;/code&gt;. A bit strange, though, that
it seems like this actually is the most straight-forward of naming the list resulting from
lapply.&lt;/p&gt;&lt;/div&gt;</description><category>contrastive linguistics</category><category>lapply</category><category>r</category><guid>https://hrmJ.github.io/blog/posts/the-setnames-%2B-lapply-pattern/</guid><pubDate>Sat, 13 Jan 2018 11:28:19 GMT</pubDate></item></channel></rss>